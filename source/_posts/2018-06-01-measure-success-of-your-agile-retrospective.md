---
title: Measure success of your agile retrospective
layout: post
comments: true
tags:
  - agile
  - retrospectives
image: /assets/article_images/measure-success-of-your-agile-retrospective/hero.png
---

This article is targeted to folks that have been participating in retrospectives and wondered "what's the point of this meeting?" and to retrospectives facilitators/scrum masters that want to learn when/how to measure retrospective engagement and success metrics.

Retrospectives should be a core practice for any team but **you must have a way to measure how successful they are** and how engaged the team is otherwise they become just another meeting.

You retrospective must be safe or people won't speak their mind. I gave a 20 minutes talk at the Sydney Pivotal office about [How to measure retrospective success](https://www.youtube.com/watch?v=0hatxoP-MU0) where I touch on how to check your retrospective safety and how to improve it.

## Why we run retrospectives?

To get in the right mindset for a retrospective the team must understand and agree that today **we know more then we did last week**. We know more of what work for us as well as what doesn't work.

I like to point to the agile manifesto:

>> At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly. 

You want to do it **at regular intervals** because doing it "when we need it" is like seeking urgent dentist care after you pop a decade old filling--and half your tooth--instead of preventing that by doing regular checkups. Regular intervals will allow you to measure how the team feel about retrospective--more on this later.

And you want the team to **reflect on how to become more effective**. Take time to collect hard data and feelings then look for patterns. Generate insights. Take time to reflect and don't rush in to finding a solution for each item that comes up like if you were playing a whack a mole game.

## Measure your retrospective success

You want to commit the team to **tune and adjust its behaviour** with an agreed and measurable experiment.

I like to use the S.M.A.R.T. experiment--SMART is a simple acronym to remind us to come up with an experiment that is:

### Specific:

**We should pair program more** isn't very specific. Instead use: **Pair program everyday 4 hours per day**.

### Measurable:

You can measure how many times you **Pair program 4 hours per day**. You should also measure hard data like velocity, delivered stories, bugs. This measurement should be quantitative and somewhat related to how effective your team is.

### Achievable:

Use an experiment that generate consensus with the team. It won't be a good idea to come up with **Pair program everyday 8 hours per day** when you know people are skeptic about it. Find a more suitable experiment, maybe **Pair program 2 days per weeek**.

Use an experiment that makes the team step out of their confort zone but is not trying to fix things clearly out of reach. 

### Relevant:

Why do you want to pair program? Because someone told you so? Not very relevant or meaningful. Perhaps someone called out that **Jack was sick 4 days and we could not work on the iOS react native UI components** and also **designers are not available to clarify how things user interface should work** so you might **want to break knowledge silos that block team progress**. Well that's one great usage of pair programming!

### Timebound:

Do not use an open ended experiment. Make sure there is an end to it like **we will try pair programming for 2 weeks** and then decide to continue or adjust the experiment. Having a timebound experiment should create common ground between optimits and skeptics and facilitate trying new things.

Here's our measurable SMART experiment:

>> We want to break knowledge silos that often block our team progress. In order to do that developers will pair program 4 hours a day for the next 2 weeks. Designers will pair program 1hour a day with devs to clarify and learn app internal behaviour. We will keep track of how many times we do that on the pair programming sheet on our shared workspace. In 2 weeks we will review this experiment and decide if we want to continue or adujust it.

---

## Measure team engagement (ESVP)

**When you start retrospective** you should spend 5/10 minutes measuring the team engagement. Depending on how safe it is you can make it anonymous or not.

I like to use an activity called E.S.V.P. to do that. You ask the team which role represents best how they feel about today's retrospective:

### Explorers

They want to make the most out of today's retrospective. Learn everything they can about the iteration/project, leave no stone unturned.

### Shoppers

They're happy to be part of the retrospective and want to actively look for something to put in their cart.

### Vacationers

They're not interested in retrospective but they rather be in it then doing actual work at their desk.

### Prisoners

They've been forced to sit in this meeting but don't see a point in it and won't be actively participating.


Collecting these at regular intervals will allow you to learn when the team is shifting from engaged to disengaged and adjust your retrospective accordingly. It will also allow you to celebrate when the team shifts the other way around! Learn what you're doing well and try do more of it or **share it with other teams in your organization**.


## Measure the return of time invested (ROTI)

**Before you finish retrospective** you should spend 5/10 minutes measuring how well spent the time was. I usually ask the team how was the return of time invested for this meeting between 0 and 4 where

### 4 ~> Excellent

Means this meeting was invaluable and if you skipped it you would have missed some key piece of information. You're very glad you were in it.

### 3 ~> Above average

This meeting was a good use of your time you learned new things.

### 2 -> Average

This meeting gave you enough to justify your presence for the time spent on it.

### 1 -> Useful

You wasted time. This meeting was below average and wasn't worth 100% of your time.

### 0 -> Useless

This meeting was a waste of time. You gained nothing and wished you skipped it.

After they pick one ask one suggestion/idea to improve by one point. The retrospective is coming to an end so you should not start long discussions about those ideas. This is a brainstorming session where you collect individual ideas to adjust the next retro. Timebox each person to 60 seconds.

---

Making your team more effective doesn't need to tackle huge issues all the time. What is critical is to measure the experiment progress so the team can trust retrospective to be a meaningful tool for adjusting their process. Ignoring how the team feels about retro, failing to measure the experiment--or taking on unachievable tasks--is going to make retrospective just another status meeting.
